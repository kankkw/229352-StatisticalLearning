{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kankkw/229352-StatisticalLearning/blob/main/Lab02.ipynb%20\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_50o8bV-nMaF"
      },
      "source": [
        "### Statistical Learning for Data Science 2 (229352)\n",
        "#### Instructor: Donlapark Ponnoprat\n",
        "\n",
        "#### [Course website](https://donlapark.pages.dev/229352/)\n",
        "\n",
        "## Lab #3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tShvCHLSAsu6"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "train = fetch_20newsgroups(subset='train')\n",
        "test = fetch_20newsgroups(subset='test')\n",
        "\n",
        "Xtrain = train.data[:3000]\n",
        "ytrain = train.target[:3000]\n",
        "Xtest = test.data[:500]\n",
        "ytest = test.target[:500]\n",
        "\n",
        "print(\"X:\", len(Xtest))\n",
        "print(\"y:\", len(ytest))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DunmeISuAxVp"
      },
      "outputs": [],
      "source": [
        "print(\"X[0]:\", Xtrain[0])\n",
        "print(\"y[0]:\", ytrain[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJF0Yf8kA4ZM"
      },
      "outputs": [],
      "source": [
        "train.target_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKIW_iS8A8KO"
      },
      "source": [
        "### Apply Tfidf ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# define transformation\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "# fit + transform training set\n",
        "Xtrain_tfidf = tfidf.fit_transform(Xtrain)\n",
        "\n",
        "# See output\n",
        "Xtrain_tfidf"
      ],
      "metadata": {
        "id": "8WvQ0M6XCFhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGt73o2UA_Xg"
      },
      "outputs": [],
      "source": [
        "#tfidf.vocabulary_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6INbp7D-B8G-"
      },
      "source": [
        "#### Exercise 1: Find post in the training set that is closest in tf-idf to the first post in the test set (`Xtest[0]`). Print the content of both posts (not the tf-idf vectors)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# transform the test post\n",
        "test_vec = tfidf.transform([Xtest[0]])\n",
        "\n",
        "# compute similarity with all training posts\n",
        "sims = cosine_similarity(test_vec, Xtrain_tfidf)[0]\n",
        "\n",
        "# index of most similar post\n",
        "idx = sims.argmax()\n",
        "\n",
        "print(\"Most similar training post index:\", idx)\n",
        "print(\"\\n---- TEST POST ----\")\n",
        "print(Xtest[0])\n",
        "print(\"\\n---- TRAIN POST ----\")\n",
        "print(Xtrain[idx])"
      ],
      "metadata": {
        "id": "p8GP8_I-DIJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The TF-IDF similarity search shows that the training post at index idx is the closest to the first test post.\n",
        "Both posts discuss similar topics and share important keywords, resulting in a high cosine similarity score.\n",
        "\n",
        "This confirms that TF-IDF + cosine similarity can identify documents with similar content even though the posts are different texts.\n"
      ],
      "metadata": {
        "id": "kehkfCIpDQRH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pPpNJ89A_pu"
      },
      "source": [
        "### Classify with k-Nearest Neighbor (kNN) ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Define model\n",
        "nb = KNeighborsClassifier(n_neighbors=5, metric='minkowski')\n",
        "\n",
        "# Fit the model\n",
        "nb.fit(Xtrain_tfidf, ytrain)"
      ],
      "metadata": {
        "id": "w0miRVWFCciA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKj8LWkYBFkY"
      },
      "source": [
        "Evaluate on the test set using [`classification_report`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)\n",
        "\n",
        "We will focus on the [F1-score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Transform the test set\n",
        "Xtest_tfidf = tfidf.transform(Xtest)\n",
        "\n",
        "# Make predictions on the test set\n",
        "ypred = nb.predict(Xtest_tfidf)\n",
        "\n",
        "# report classification scores\n",
        "print(classification_report(ytest, ypred))"
      ],
      "metadata": {
        "id": "0I5IzQj1CipT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNQlI-b7BJyb"
      },
      "source": [
        "### Combine all methods into a [pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
        "    ('knn', KNeighborsClassifier())\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training set\n",
        "pipeline.fit(Xtrain, ytrain)\n",
        "\n",
        "# Make predictions on the test set\n",
        "ypred = pipeline.predict(Xtest)\n",
        "\n",
        "# report classification scores\n",
        "print(classification_report(ytest, ypred))"
      ],
      "metadata": {
        "id": "caBgQ7BtCnht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHEZHkyaBNU6"
      },
      "source": [
        "Now we will use [grid search cross-validation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) to find model with the best hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmE7nqYPEy-G"
      },
      "source": [
        "![5CV](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params = {\n",
        "    'tfidf__stop_words': ['english'],\n",
        "    'knn__n_neighbors': [3, 5, 7, 9],\n",
        "    'knn__metric': ['minkowski', 'cosine']\n",
        "}\n",
        "\n",
        "# Define GridSearchCV\n",
        "gridcv = GridSearchCV(\n",
        "    estimator=pipeline,\n",
        "    param_grid=params,\n",
        "    scoring='f1_macro',\n",
        "    cv=3\n",
        ")\n",
        "\n",
        "# Fit and cross-validate the model on 3-fold data\n",
        "gridcv.fit(Xtrain, ytrain)"
      ],
      "metadata": {
        "id": "8P2lUDgfCtHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCd-8EFBBR5F"
      },
      "outputs": [],
      "source": [
        "gridcv.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "ypred = gridcv.predict(Xtest)\n",
        "\n",
        "# Report classification scores\n",
        "print(classification_report(ytest, ypred))"
      ],
      "metadata": {
        "id": "qKiIdorFC3K8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtcscwZPBRJ2"
      },
      "source": [
        "#### Exercise 2:\n",
        "\n",
        "1. Use grid search 5-fold cross-validation across different values of the following two kNN parameters: `n_neighbors` and `metric`  **on the training set** to find the best model.\n",
        "\n",
        "2. For the best value of `n_neighbors` and `metric` you found above, compute the `f1_macro` score **on the test set**.\n",
        "* Print the value of `n_neighbors` and `metric`.\n",
        "* Print the model's `f1_macro` score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U97-Uu5-BTxj"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'tfidf__stop_words': ['english'],\n",
        "    'knn__n_neighbors': [3, 5, 7, 9, 11],\n",
        "    'knn__metric': ['minkowski', 'cosine']\n",
        "}\n",
        "\n",
        "grid5 = GridSearchCV(\n",
        "    estimator=pipeline,\n",
        "    param_grid=param_grid,\n",
        "    scoring='f1_macro',\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "grid5.fit(Xtrain, ytrain)\n",
        "\n",
        "print(\"Best n_neighbors:\", grid5.best_params_['knn__n_neighbors'])\n",
        "print(\"Best metric:\", grid5.best_params_['knn__metric'])\n",
        "\n",
        "# evaluate on test set\n",
        "ypred = grid5.predict(Xtest)\n",
        "print(classification_report(ytest, ypred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "ypred = grid5.predict(Xtest)\n",
        "\n",
        "print(\"F1_macro on test set:\", f1_score(ytest, ypred, average='macro'))"
      ],
      "metadata": {
        "id": "yKlqWAii092B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this exercise, a 5-fold grid search is used to find the best values of n_neighbors and metric for the kNN classifier. The model is evaluated using the macro F1 score on the training set to ensure balanced performance across all classes. After identifying the optimal hyperparameters, the model is tested on unseen data, and its performance is reported using the F1_macro score. This process illustrates how grid search and cross-validation help in selecting the most effective model for multi-class text classification.\n"
      ],
      "metadata": {
        "id": "SoHxHvu41BSc"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}