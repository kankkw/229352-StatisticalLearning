{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kankkw/229352-StatisticalLearning/blob/main/Lab05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73fc9e9c-da15-4994-9f19-77497e9813cd",
      "metadata": {
        "id": "73fc9e9c-da15-4994-9f19-77497e9813cd"
      },
      "source": [
        "### Statistical Learning for Data Science 2 (229352)\n",
        "#### Instructor: Donlapark Ponnoprat\n",
        "\n",
        "#### [Course website](https://donlapark.pages.dev/229352/)\n",
        "\n",
        "## Lab #6"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ceb0ebd5-f2fa-464d-9ccb-5030b9729ac5",
      "metadata": {
        "id": "ceb0ebd5-f2fa-464d-9ccb-5030b9729ac5"
      },
      "source": [
        "## Support Vector Machines (SVM)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f4351f5-a63a-47f6-b567-c549f8f0495a",
      "metadata": {
        "id": "0f4351f5-a63a-47f6-b567-c549f8f0495a"
      },
      "source": [
        "[SVM module documentation](https://scikit-learn.org/stable/modules/svm.html#svm)\n",
        "\n",
        "[LinearSVC documentation](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC)\n",
        "\n",
        "[SVC documentation](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "145006ec-424f-437d-883e-a2c8257a3c93",
      "metadata": {
        "id": "145006ec-424f-437d-883e-a2c8257a3c93"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import LinearSVC  # fast but only linear\n",
        "from sklearn.svm import SVC  # slower but can do kernels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7eaa1514-dff9-4dee-a40e-17c26a0337b7",
      "metadata": {
        "id": "7eaa1514-dff9-4dee-a40e-17c26a0337b7"
      },
      "outputs": [],
      "source": [
        "# Load the iris data\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data[:, 2:]\n",
        "y = iris.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4858a66-cda5-4f7b-b955-21132bfa0be6",
      "metadata": {
        "id": "b4858a66-cda5-4f7b-b955-21132bfa0be6"
      },
      "outputs": [],
      "source": [
        "# Plot the data\n",
        "plt.figure(figsize=(7,6))\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
        "plt.xlabel(iris.feature_names[2])\n",
        "plt.ylabel(iris.feature_names[3])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da3651c6-91b3-44a9-977b-5c4bc1c332ad",
      "metadata": {
        "id": "da3651c6-91b3-44a9-977b-5c4bc1c332ad"
      },
      "source": [
        "#### In this problem, you'll use support vector machines to classify the Iris data\n",
        "\n",
        "#### The following function helps you plot the decision boundary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5949c584-42d0-4a09-8bbd-3a876d1c8993",
      "metadata": {
        "id": "5949c584-42d0-4a09-8bbd-3a876d1c8993"
      },
      "outputs": [],
      "source": [
        "# Plot the decision boundaries\n",
        "def plot_decision_boundary(clf, X, y):\n",
        "    h = 0.005  # Boundary lines' resolution\n",
        "    x_min, x_max = X[:,0].min() - 10*h, X[:,0].max() + 10*h\n",
        "    y_min, y_max = X[:,1].min() - 10*h, X[:,1].max() + 10*h\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                         np.arange(y_min, y_max, h))\n",
        "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    plt.figure(figsize=(7,6))\n",
        "    plt.contourf(xx, yy, Z, alpha=0.25)  # Background\n",
        "    plt.contour(xx, yy, Z, colors='k', linewidths=0.2)  # Boundary lines\n",
        "    plt.scatter(X[:,0], X[:,1], c=y);  # Data points\n",
        "    plt.xlabel(iris.feature_names[2])\n",
        "    plt.ylabel(iris.feature_names[3])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45547faa-82b6-49c1-ad52-cf9e65a953f0",
      "metadata": {
        "id": "45547faa-82b6-49c1-ad52-cf9e65a953f0"
      },
      "source": [
        "#### Exercise 1. Split the data into training set and test set."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")"
      ],
      "metadata": {
        "id": "-oPdmCe1B_K3"
      },
      "id": "-oPdmCe1B_K3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "36f49e86-2e59-4b08-b384-139a04bba30a",
      "metadata": {
        "id": "36f49e86-2e59-4b08-b384-139a04bba30a"
      },
      "source": [
        "#### Exercise 2. Learn a linear SVM classifier using sklearn.svm.LinearSVC. You will need to set `loss='hinge'`.\n",
        "\n",
        "#### Try different values of the tradeoff parameter: `C = 0.01, 0.1, 1.0, 10.0, 100.0` and use `plot_decision_boundary` to plot the decision boundary.\n",
        "\n",
        "#### If you encounter `RuntimeError`, consider setting `max_iter=100000`\n",
        "\n",
        "#### What is the effect of `C` on the decision boundary?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_values = [0.01, 0.1, 1.0, 10.0, 100.0]\n",
        "\n",
        "for C in C_values:\n",
        "    clf = LinearSVC(C=C, loss='hinge', max_iter=100000)\n",
        "    clf.fit(X_train, y_train)\n",
        "    plot_decision_boundary(clf, X_train, y_train)\n",
        "    plt.title(f\"Linear SVM (C = {C})\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ceHQm9CDCHU1"
      },
      "id": "ceHQm9CDCHU1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Effect of C:\n",
        "Smaller C gives a wider margin and smoother decision boundary (more regularization).\n",
        "Larger C gives a narrower margin and fits the training data more strictly."
      ],
      "metadata": {
        "id": "DbCVdoavCwkX"
      },
      "id": "DbCVdoavCwkX"
    },
    {
      "cell_type": "markdown",
      "id": "170e615a-71d3-430a-89b0-0180978068fd",
      "metadata": {
        "id": "170e615a-71d3-430a-89b0-0180978068fd"
      },
      "source": [
        "#### Exercise 3. Pick a value of `C` that you like. Then report the test error."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C = 1.0\n",
        "clf = LinearSVC(C=C, loss='hinge', max_iter=100000)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "test_accuracy = clf.score(X_test, y_test)\n",
        "test_error = 1 - test_accuracy\n",
        "\n",
        "test_error"
      ],
      "metadata": {
        "id": "Lv5lHJXxCrlf"
      },
      "id": "Lv5lHJXxCrlf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1d0870ac-f415-41e7-ae64-afda214e04a0",
      "metadata": {
        "id": "1d0870ac-f415-41e7-ae64-afda214e04a0"
      },
      "source": [
        "#### Exercise 4. Now try kernel SVM with a quadratic kernel. You can do this with sklearn.svm.SVC, setting `kernel='rbf'` and `C = 1.0`.\n",
        "\n",
        "#### Try different values of the tradeoff parameter: `gamma = 0.01, 0.1, 1.0, 10.0, 100.0` and use `plot_decision_boundary` to plot the decision boundary.\n",
        "\n",
        "#### If you encounter `RuntimeError`, consider setting `max_iter=100000`\n",
        "\n",
        "#### What is the effect of `gamma` on the decision boundary?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gamma_values = [0.01, 0.1, 1.0, 10.0, 100.0]\n",
        "\n",
        "for gamma in gamma_values:\n",
        "    clf = SVC(kernel='rbf', C=1.0, gamma=gamma, max_iter=100000)\n",
        "    clf.fit(X_train, y_train)\n",
        "    plot_decision_boundary(clf, X_train, y_train)\n",
        "    plt.title(f\"RBF SVM (gamma = {gamma})\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "hJYzUZxnCjW5"
      },
      "id": "hJYzUZxnCjW5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Effect of gamma:\n",
        "Small gamma gives a smoother and more global decision boundary.\n",
        "Large gamma gives a more complex and localized decision boundary, risking overfitting."
      ],
      "metadata": {
        "id": "vYWsvZ-BCktV"
      },
      "id": "vYWsvZ-BCktV"
    },
    {
      "cell_type": "markdown",
      "id": "0ec823cb-0601-4e3c-966c-e42d862c7837",
      "metadata": {
        "id": "0ec823cb-0601-4e3c-966c-e42d862c7837"
      },
      "source": [
        "#### Exercise 5. Pick a value of `gamma` that you like. Then report the test error and the number of support vectors."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gamma = 0.1\n",
        "clf = SVC(kernel='rbf', C=1.0, gamma=gamma)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "test_accuracy = clf.score(X_test, y_test)\n",
        "test_error = 1 - test_accuracy\n",
        "num_support_vectors = clf.n_support_.sum()\n",
        "\n",
        "test_error, num_support_vectors"
      ],
      "metadata": {
        "id": "03R4LxUnCfcD"
      },
      "id": "03R4LxUnCfcD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f33770ff-ef21-43bf-9982-ccf95f0a674d",
      "metadata": {
        "id": "f33770ff-ef21-43bf-9982-ccf95f0a674d"
      },
      "source": [
        "#### Exercise 6. Between Linear SVM and Kernel SVM, which model would you prefer to use for classification of Iris data?\n",
        "1. Explain using test accuracy\n",
        "2. Explaing using decision boundary plot"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preferred model: Kernel SVM (RBF)\n",
        "\n",
        "1. Explanation using test accuracy:\n",
        "Kernel SVM achieves higher test accuracy than Linear SVM.\n",
        "\n",
        "2. Explanation using decision boundary:\n",
        "Kernel SVM provides a nonlinear decision boundary that better separates the Iris classes,\n",
        "while Linear SVM is limited to linear separation."
      ],
      "metadata": {
        "id": "HA5VwsWGCPLd"
      },
      "id": "HA5VwsWGCPLd"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}